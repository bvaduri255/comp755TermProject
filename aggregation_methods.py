# -*- coding: utf-8 -*-
"""Aggregation Methods

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18jhhGL4YXviNUwLeptDRtMqTc7bbfSOY
"""

import numpy as np
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neural_network import MLPRegressor, MLPClassifier
from scipy.stats import laplace

class LinearRegressionFederated:
    def __init__(self, models, dataset_sizes, accuracies):
        if not (len(models) == len(dataset_sizes) == len(accuracies)):
            raise ValueError("All input lists must be of the same length.")

        self.models = models
        self.dataset_sizes = np.array(dataset_sizes)
        self.accuracies = np.array(accuracies)

    def equal_weight_average(self):
        coefficients = [model.coef_ for model in self.models]
        intercepts = [model.intercept_ for model in self.models]

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return avg_coef, avg_intercept

    def dataset_size_weighted_average(self):
        weights = self.dataset_sizes / self.dataset_sizes.sum()
        return self.weighted_average(weights)

    def accuracy_weighted_average(self):
        weights = self.accuracies / self.accuracies.sum()
        return self.weighted_average(weights)

    def clipped_average(self, clip_range):
        coefficients = np.clip([model.coef_ for model in self.models], clip_range[0], clip_range[1])
        intercepts = np.clip([model.intercept_ for model in self.models], clip_range[0], clip_range[1])

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return avg_coef, avg_intercept

    def differential_privacy_average(self, epsilon):
        coefficients = [model.coef_ + laplace.rvs(scale=1/epsilon) for model in self.models]
        intercepts = [model.intercept_ + laplace.rvs(scale=1/epsilon) for model in self.models]

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return avg_coef, avg_intercept

    def weighted_average(self, weights):
        weighted_coefs = [coef * w for coef, w in zip([model.coef_ for model in self.models], weights)]
        weighted_intercepts = [intercept * w for intercept, w in zip([model.intercept_ for model in self.models], weights)]

        avg_coef = np.sum(weighted_coefs, axis=0) / weights.sum()
        avg_intercept = np.sum(weighted_intercepts) / weights.sum()

        return avg_coef, avg_intercept

    def create_model(self, coef, intercept):
        model = LinearRegression()
        model.set_params(coef, intercept)
        return model

class LogisticRegressionFederated:
    def __init__(self, models, dataset_sizes, accuracies):
        if not (len(models) == len(dataset_sizes) == len(accuracies)):
            raise ValueError("All input lists must be of the same length.")

        self.models = models
        self.dataset_sizes = np.array(dataset_sizes)
        self.accuracies = np.array(accuracies)

    def create_model(self, coef, intercept):
        model = LogisticRegression()
        model.set_params(coef, intercept)
        return model

    def calculate_average(self):
        coefficients = [model.coef_[0] for model in self.models]  # Logistic regression coef_ is 2D
        intercepts = [model.intercept_[0] for model in self.models]

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return avg_coef, avg_intercept

    def weighted_average(self, weights):
        weighted_coefs = [coef * w for coef, w in zip([model.coef_[0] for model in self.models], weights)]
        weighted_intercepts = [intercept * w for intercept, w in zip([model.intercept_[0] for model in self.models], weights)]

        avg_coef = np.sum(weighted_coefs, axis=0) / weights.sum()
        avg_intercept = np.sum(weighted_intercepts) / weights.sum()

        return avg_coef, avg_intercept

    def equal_weight_average(self):
        avg_coef, avg_intercept = self.calculate_average()
        return self.create_model(avg_coef, avg_intercept)

    def dataset_size_weighted_average(self):
        weights = self.dataset_sizes / self.dataset_sizes.sum()
        weighted_coef, weighted_intercept = self.weighted_average(weights)
        return self.create_model(weighted_coef, weighted_intercept)

    def accuracy_weighted_average(self):
        weights = self.accuracies / self.accuracies.sum()
        weighted_coef, weighted_intercept = self.weighted_average(weights)
        return self.create_model(weighted_coef, weighted_intercept)

    def clipped_average(self, clip_range):
        coefficients = np.clip([model.coef_[0] for model in self.models], clip_range[0], clip_range[1])
        intercepts = np.clip([model.intercept_[0] for model in self.models], clip_range[0], clip_range[1])

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return self.create_model(avg_coef, avg_intercept)

    def differential_privacy_average(self, epsilon):
        coefficients = [model.coef_[0] + laplace.rvs(scale=1/epsilon) for model in self.models]
        intercepts = [model.intercept_[0] + laplace.rvs(scale=1/epsilon) for model in self.models]

        avg_coef = np.mean(coefficients, axis=0)
        avg_intercept = np.mean(intercepts)

        return self.create_model(avg_coef, avg_intercept)

class NeuralNetworkFederated:
    def __init__(self, models, dataset_sizes, accuracies):
        if not (len(models) == len(dataset_sizes) == len(accuracies)):
            raise ValueError("All input lists must be of the same length.")

        self.models = models
        self.dataset_sizes = np.array(dataset_sizes)
        self.accuracies = np.array(accuracies)

    def create_model(self, weights, biases):
        model = MLPClassifier()
        model.set_params(weights, biases)
        return model

    def calculate_average(self):
        weights = [model.coefs_[0] for model in self.models]
        biases = [model.intercepts_[0] for model in self.models]

        avg_weights = np.mean(weights, axis=0)
        avg_biases = np.mean(biases, axis=0)

        return avg_weights, avg_biases

    def weighted_average(self, weights):
        weighted_weights = np.average([model.coefs_[0] for model in self.models], axis=0, weights=weights)
        weighted_biases = np.average([model.intercepts_[0] for model in self.models], axis=0, weights=weights)

        return weighted_weights, weighted_biases

    def equal_weight_average(self):
        avg_weights, avg_biases = self.calculate_average()
        return self.create_model(avg_weights, avg_biases)

    def dataset_size_weighted_average(self):
        weights = self.dataset_sizes / self.dataset_sizes.sum()
        weighted_weights, weighted_biases = self.weighted_average(weights)
        return self.create_model(weighted_weights, weighted_biases)

    def accuracy_weighted_average(self):
        weights = self.accuracies / self.accuracies.sum()
        weighted_weights, weighted_biases = self.weighted_average(weights)
        return self.create_model(weighted_weights, weighted_biases)

    def clipped_average(self, clip_range):
        weights = np.clip([model.coefs_[0] for model in self.models], clip_range[0], clip_range[1])
        biases = np.clip([model.intercepts_[0] for model in self.models], clip_range[0], clip_range[1])

        avg_weights = np.mean(weights, axis=0)
        avg_biases = np.mean(biases, axis=0)

        return self.create_model(avg_weights, avg_biases)

    def differential_privacy_average(self, epsilon):
        weights = [model.coefs_[0] + laplace.rvs(scale=1/epsilon, size=model.coefs_[0].shape) for model in self.models]
        biases = [model.intercepts_[0] + laplace.rvs(scale=1/epsilon, size=model.intercepts_[0].shape) for model in self.models]

        avg_weights = np.mean(weights, axis=0)
        avg_biases = np.mean(biases, axis=0)

        return self.create_model(avg_weights, avg_biases)



def(gradient, weights):

[client_gradients[1] for client_gradients in gradients]